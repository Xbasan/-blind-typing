Preface In recent years the subject of computer programming has been recognized as a discipline whose mastery is fundamental and crucial to the success of many engineering projects and which is amenable to scientific treatement and presentation. It has advanced from a craft to an academic discipline. The initial outstanding contributions toward thi 
Both these papers argue convincingly that many programming errors can be prevented by making programmers aware of the methods and techniques which they hitherto applied intuitively and often unconsciously. These papers focused their attention on the aspects of composition and analysis of programs The essence of this theory is that data in the first 
In the process of program construction the data representation is gradually refined in step with the refinement of the algorithm to comp A cornerstone of this theory of data structures is the distinction between fundamental and "advanced" structures. The former are the molecules themselves built out of atoms that are the components of the latter. 
Variables of a fundamental structure change only their value More sophisticated techniques are therefore needed for their implementation. The sequence appears as a hybrid in this classification. It certainly varies its length; but that change in structure is of a trivial nature. Since the sequence plays a truly fundamental role in practically all 
The space allocated to sorting would not be so large were it not for the fact that sorting constitutes an ideal vehicle for illustrating so many principles of programming and situations occurring in most other applications. It often seems that one could compose an entire programming course by choosing examples from sorting only. Another topic that 
One method is to crystallize elementary composition principles out of many cases and exhibit them in a systematic manner. But programming is a field of vast variety often involving complex intellectual activities. The belief that it could ever be condensed into a sort of pure recipe teaching is mistaken. What remains in our arsenal of teaching meth 
Edition This new Edition incorporates many revisions of details and several changes of more significant nature. They were all motivated by experiences made in the ten years since the first Edition appeared. Most of the contents and the style of the text In this section in particular we use assertions and loop invariants to demonstrate the 
A new section on priority search trees rounds off the chapter on dynamic data structures. Also this species of trees was unknown when the first Edition appeared. They allow an economical representation and a fast search of Introduction The modern digital computer was invented and intended as a device that should facilitate and speed up complicated 
In the majority of applications its capability to store and access large amounts of information plays the dominant part and is considered to be its primary characteristic The data represent an abstraction of reality in the sense that certain properties and characteristics of the real objects are ignored because they are peripheral and irrelevant to 
An abstraction is thereby also a simplification of facts. We may regard a personnel file of an employer as an example. Every employee is represent The decomposition of these operations into simpler ones is much easier in the case of representation by Arabic numerals because of their systematic structuring principle that is based on positional 
It is generally known that computers use an internal representation based on binary digits The importance of using a language that offers a convenient set of basic abstractions common to most problems of data processing lies mainly in the area of reliability of the resulting programs. It is easier to design a program based on reasoning with 
But it is exactly this abstract structure which alone is enabling human programmers to recognize meaning in the monotonous landscape of a computer store. The theory presented in this book and the programming language Oberon specify certain methods of defining data types. In most cases new data types are defined in terms of previously defined data t 
The resulting value may be outside the interval specified as the range of indices of the array. We will assume that decent computing systems provide a warning in the case of such a mistaken access to a non-existent array component. The cardinality of a structured type But even more important is the possibility to use effective buffering techniques 
Sequential access allows us to feed streams of data through pipes between the different media. Buffering implies the collection of sections of a stream in a buffer Here we will use the term file as synonym to sequence. There exist certain storage media in which the sequential access is indeed the only possible one. Among them are evidently all 
But even on magnetic disks each recording track constitutes a storage facility allowing only sequential access. Strictly sequential access is the primar The execution of these actions will merely have to be delayed until the guarding conditions are established. Such delays essentially constitute the necessary synchronization among concurrent 
We may represent these delays respectively by the statements REPEAT UNTIL n < N REPEAT UNTIL n > The choice of m is apparently arbitrary in the sense that correctness does not depend on it. But it does influence the algorithm's effectiveness. Clearly our goal must be to eliminate in each step as many elements N.Wirth. Algorithms and Data 
Structures. Oberon version A specific feature of this problem is the presence of two arrays and a necessity to scan them simultaneously in such a way that the coordination of the two indices used to scan the arrays is determined by the data. A correct implementation of such "braided" loops is simplified by expressing them using the so-called 
Dijkstra's loop Shifting pattern past position of last character The essential result is that the value D apparently is determined by the pattern alone and does not depend on the text string. We shall denote D for a given j as dj. The auxiliary table d may be computed before starting the actual search; this computation amounts to a precompilation 
T BM search. We shall here present a simplified version of BM-search before proceeding to the one given by Boyer and Moore. BM-search is based on the unconventional idea to start comparing characters at the end of the pattern rather than at the beginning. Like in the case of KMP-search Given a text T in the form of a sequence and lists of a small 
A and B. Assume that words are short arrays of characters of a small and fixed maximum length. Write a program that transforms the text T into a text S by replacing each occurrence of a word Ai by its corresponding word Bi. Four separate lists with the names and first names of all respondents who had mentioned in first place one of the three hits 
The five lists are to be preceded by suitable titles. N.Wirth. Algorithms and Data Structures. Oberon version Introduction The primary purpose of this chapter is to provide an extensive set of examples illustrating the use of the data structures introduced in the preceding chapter and to show how the choice of structure for the underlying data 
Sorting is also a good example to show that such a It is therefore an ideal subject to demonstrate the necessity of performance analysis of algorithms. The example of sorting is moreover well suited for showing how a very significant gain in performance may be obtained by the development of sophisticated algorithms when obvious methods are readily 
Fig. Straight insertion considers in each step only the one next item of the source sequence and all items of the destination array to find the insertion point; straight selection considers all items of the source array to find the one with the least key and to be deposited as the one next item of the destination sequence. PROCEDURE 
StraightSelection; An obvious technique for improving this algorithm is to remember whether or not any exchange had taken place during a pass. A last pass without further exchange operations is therefore necessary to determine that the algorithm may be terminated. However Bubblesort has hardly anything to recommend it except its catchy name. The 
Shakersort algorithm is used with advantage in those cases in which it is known that the items are already almost in order - a rare case in practice. It can be shown that the average distance that each of the n items has to travel during a sort is n/ This will avoid the phenomenon evident from the example given above in which each sorting pass 
It is indeed desirable that interaction between various chains takes place as often as possible The reader is urged to convince himself that the proposed method of sifting actually preserves the heap invariants that define a heap. A neat way to construct a heap in situ was suggested by R. W. Floyd. It uses the sifting procedure shown below. Given 
The array with all identical keys would cause the scans to go beyond the bounds of the array unless more complicated termination conditions were used. The simplicity of the conditions is well worth the extra exchanges that occur relatively rarely in the average random case. A slight saving It becomes evident that sorting on the basis of Quicksort 
There is one important lesson to be learned from this experience; it concerns the programmer directly. What are the consequences of the worst case behavior mentioned above to In the further refinement step the actual merge statement is to be formulated. Here we have to keep in mind that the tail of the one subsequence which is left non-empty after 
WHILE Which parts of the algorithm are affected by this relaxation of constraints? We easily convince ourselves that the best way to cope with the more general situation is to adhere to the old method as long as possible. In this example this means that we continue merging p-tuples until the remainders of the source sequences are of length less 
T OpenRandomSeq initializes a file with numbers in random order. These two procedures will serve to test the algorithms to be discussed below. The values of the fields eof and eor are defined as results of copy in analogy to eof having been defined as result of a read operation. MODULE Runs; Incorrect Result of MergeSort Program. The example of 
The mistake is caused by an oversight of one of the possible consequences of a presumably simple operation. It is also typical in the sense that serval ways of correcting the mistake are open and that one of them has to be chos Polyphase Sort We have now discussed the necessary techniques and have acquired the proper background to investigate and 
We have seen that balanced merging eliminates the pure copying operations necessary when the distribution and the merging operations are un The most typical representative is the combination of a process that produces a stream of information in distinct entities and a process that consumes this stream. This producer-consumer relationship can be 
The coroutine may be considered as a process that contai END; RETURN dest END Distribute Analysis and conclusions. What performance can be expected from a Polyphase sort with initial distribution of runs by a HeapSort? We first discuss the improvement to be expected by introducing the heap. In a sequence with randomly distributed keys the expected 
Programs in which the use of algorithmic recursion is to be avoided can be characterized by a schema which exhibits the pattern of their composition. The equivalent schemata are shown below. Their characteristic is that there is only a single call of P either at the end WHILE B DO S END] There also exist more complicated recursive composition 
An example is the computation of the Fibonacci numbers which are defined by the recurrence relation N.Wirth. Algorithms and Data Structures. Oberon version The square in which the curves are drawn is placed into the middle of the page with given width and height. These parameters as well as the drawing procedure line are taken from a module Draw. 
Note that this module retains the current position of the pen. DEFINITION Draw; C and D are derived analogously. The main program is composed according to the base pattern. Its task is to set the initial values for the drawing coordinates and to determine the unit line length h according to the size of the plane. The result of executing this 
The common pattern is to decompose the trial-and-error process onto partial tasks. Often these tasks are most naturally expressed in recursive terms and consist of the exploration of a finite number of subtasks. We may generally view the entire process as a trial or search process that gradually builds up and scans Introducing such complications is 
The predicate tour can be completed from this candidate is conveniently expressed as a function- procedure that returns a logical value. Since it is necessary to record the sequence of moves being generated At this point we can make decisions about the appropriate parameters for the two procedures TryNextMove and CanBeDone. The parameters of 
TryNextMove are to determine the starting conditions for the next move and also to report on its success. The former task is adequately solved by specifying the coordinates x The function-procedure CanBeDone expresses the predicate tour can be completed from this move and is used within TryNextMove in the linear search over possible move 
Introduce two local variables u and v to stand for the coordinates of the move destinations examined by the linear sear OF INTEGER The decision to represent each field of the board by an integer instead of a Boolean value denoting occupation allows to record the history of successive board occupations in the simplest fashion. The following 
END Next The enumeration of candidate moves is accomplished in a similar procedure First that generates the first candidate move; see the details in the final program presented below. Just one more refinement step will lead us to a program expressed fully in terms of our basic programming notation. We should note that so far the program was develop 
Three Knights' Tours. What abstractions can now be made from this example? Which pattern does it exhibit that is typical for this kind of problem-solving algorithms? What does it teach us? The characteristic feature is that steps toward the total solution are attempted and recorded that may later be taken back and erased in the recordings when it i 
In subsequent examples we will see variations on this theme. Note that the search condition in the while loop is modeled as a procedure-function CanBeDone for a maximal clarification of the logic of the algorithm while keeping the program easily comprehensible. N.Wirth. Algorithms and Data Structures. Oberon version OF BOOLEAN where xi denotes the 
We note that in a /-diagonal all fields have the same sums of their coordinates i and j The extension is easily accommodated. We are to recall the fact that the generation of candidates must progress in a systematic manner that guarantees no candidate is generated more than once. This property N.Wirth. Algorithms and Data Structures. Oberon version 
It allows — once a solution is found and duly recorded — merely to proceed to the next candidate delivered by the systematic selection process. The modification is formally accomplished by carrying the procedure function CanBeDone from the loop's guard into its body and substituting the procedure body in place of its call. To return a logical value 
DO record move; Try; erase move; select next move END ELSE print solution END END Try It comes as a surprise that the search for all possible solutions is realized by a simpler program than the search for a single solution. In the eight queenn problem another simplification is posssible. Indeed A and b in B satisfy some constrains. Many different 
Assume that A is a set of men and B is a set of women. Each man and each women has stated distinct preferences for their possible partners. If the n couples are chosen such that there exists a man and a woman It is plain that the values of these auxiliary arrays are constant and can initially be determined from the values of wmr and mwr. The 
Recall that we are trying the feasibility of marrying m and w Result of the Stable Marriage Problem. The solution with the least value rm is called the male-optimal stable solution; the one with the smallest rw is the female-optimal stable solution. It lies in the nature of the chosen search strategy that good solutions from the men's point of view 
The Optimal Selection Problem The last example of a backtracking algorithm is a logical extension of the previous two examples represented by the general schema. First we were using the principle of backtracking to find a single solution to a given problem. This was exemplified by the knight's tour and the eight queens. Then we tackled the goal of 
We choose the important and frequently encountered problem of finding an optimal selection out of a given set of objects subject to constraints. Selections that constitute acceptable solutions are gradually built up by investigating individual objects from the base set. A procedure Try describes the process of investigating the suitability of one i 
This is a problem well known to all travellers who pack suitcases by selecting from n items in such a way that their total value is optimal and that their total weight does not exceed a specific allowance. We are now in a position to decide upon the representation of the given facts in terms of global variables. The choices are easily derived from 
SET The variables limw and totv denote the weight limit and the total value of all n objects. These two values are actually constant during the entire selection process. s represents the current selection of objects in which each object is represented by its name The entire procedure is now composed of the discussed parts with the addition of 
The ease of expressing inclusion and exclusion from the set s by use of set operators is noteworthy. The results opts and maxv of the program Selection with weight allowances ranging from Data structure linked by pointers It must be emphasized that the use of pointers to implement recursive structures is merely a technique. The programmer need not 
Storage may be allocated automatically the first time a new component is referenced. However It has therefore become common in advanced programming languages to make possible the explicit manipulation of references to data in addition to the data themeselves. This implies that a clear notational distinction must exist between data and references to 
Values of pointer types are generated whenever a data item is dynamically allocated. We will adhere to the convention that such an occasion be explicitly mentioned at all times. This is in contrast to the situation in which the first time that an item is mentioned it is automatically allocated. For this purpose The implementation technique using 
The common solution is to extend the range of values of all pointer types by a single value that is pointing to no element at all. We denote this value by the special symbol NIL NIL. The renaming of the type ped to Person reflects the difference in the viewpoint brought about by the introduction of explicit pointer values. Instead of first 
This situation is easily expressed by replacing the two NIL values in the respective fields of the two records. An implementation that hides the concept of pointers or uses a different technique of storage handling would force the programmer to represent the ancestor records of Adam and Evatwice. Although in accessing their data for inspection it d 
The remainder of this chapter is devoted to the generation and manipulation of data structures whose components are linked by explicit pointers. Structures with specific simple patterns are emphasized in particular; recipes for handling more complex structures may be derived from those for manipulating basic formations. These are the linear list or 
Its disadvantage is that the first element inserted has to be treated differently from all later ones. The explicit availability of pointers makes certain operations very simple which are otherwise cumbersome; among the elementary list operations are those of inserting and deleting elements END It follows from the definitions of the while statement 
P is applied to all elements of the list and to no other ones. A very frequent operation performed is list searching for an element with a given key x. Unlike for arrays The formulation of the procedure called search follows in a straightforward manner. The variable root refers to the head of the list in which new words are inserted accordingly. 
The complete algorithm is listed below; it includes a routine for tabulating the constructed cross-reference list. The tabulation process is an example in which an action i The preceding examples are therefore suitable primarily as programming exercises rather than for practical applications. The arrangement of data in a linked list is recommended 
N.Wirth. Algorithms and Data Structures. Oberon version The use of simple linked lists is appropriate for applications with relatively short programs. Even in this case a considerable improvement in access method can be achieved by a very simple technique which is mentioned here again primarily because it constitutes a pretty example for 
A ch Note that the main difference between the new algorithm and the straight list search is the action of reordering when an element has been found. It is then detached or deleted from its old position and inserted at the top. This deletion again requires the use of two chasing pointers END This completes the program for topological sorting. Note 
This count is decremented each time a leader element is output in the output phase. It should therefore return to zero at the end of the program. Its failure to return to zero is an indication that there ar We now turn to the problem of representation of trees. It is plain that the illustration of such recursive structures in terms of branching 
There is evidently no use in declaring variables with a fixed tree structure; instead Tree generated by preceding program Note the simplicity and transparency of this program that is obtained through the use of recursive procedures. It is obvious that recursive algorithms are particularly suitable when a program is to manipulate information whose 
This is again manifested in the procedure whic Basic Operations on Binary Trees There are many tasks that may have to be perfomed on a tree structure; a common one is that of executing a given operation P on each element of the tree. P is then understood to be a parameter of the more general task of visting all nodes or Let us now formulate the 
P denoting the operation to be performed on each node. Assume the following definitions Node END The three methods are now readily formulated as recursive procedures; they demonstrate again the fact that operations on recursively defined data structures are most conveniently defined as recursive algorithms. N.Wirth. Algorithms and Data Structures. 
Oberon version We shall first consider only the case of a steadily growing but never shrinking tree. A typical example is the concordance problem which was already investigated in connection with linked lists. It is now to be revisited. In this problem a sequence of words is given Insertion in ordered binary tree The search process is formulated as 
Note that its parameter p is a variable parameter and not a value parameter. This is essential because in the case of insertion a new pointer value must be assigned to the variable which previously held the value NIL. Using the input sequence of Analysis of Tree Search and Insertion It is a natural reaction to be suspicious of the algorithm of tree 
At least one should retain some skepticism until having been given a few more details about its behaviour. What worries many programmers at first is the peculiar fact that generally we do not know how the tree will grow; we Possible improvements lie in the formulation of less strict definitions of balance. Such imperfect balance criteria should 
One such definition of balance has been postulated by Adelson-Velskii and Landis [ Restoring the balance An algorithm for insertion and rebalancing critically depends on the way information about the tree's balance is stored. An extreme solution lies in keeping balance information entirely implicit in the tree structure itself. In this case The 
This is particularly true because the nodes of such search trees are usually implemented as densely packed records in order to economize storage. The speed of access and of updating th Dynamic data structures introduced in this chapter are particularly suitable for incorporation of secondary storage media. The principal innovation is merely that 
Using a binary tree for a data set of We shall now develop a detailed program from these sketchy descriptions. It is already apparent that a recursive formulation will be most convenient because of the property of the splitting process to propagate N.Wirth. Algorithms and Data Structures. Oberon version Another positive quality of the B-tree 
Every page is fetched into primary store exactly once. Deletion of items from a B-tree is fairly straight-forward in principle Q. Since this involves fetching page Q into main store — a relatively costly operation — one is tempted to make the best of this undesirable situation and to annect more than a single item at once. The usual strategy is to 
P and Q evenly on both pages. This is called page balancing. Of course They are labelled according to the directions of the horizontal pointers linking the three siblings in the middle figures. The initial situation is shown in the left column; the middle column illustrates the fact that the lower node has been raised as its subtree has grown; the 
N.Wi One is therefore inclined to compare these structures with garden hedges that have been recently trimmed with hedge scissors. The algorithm for the construction of SBB-trees is show below. It is based on a definition of the type Node with the two components lh and rhindicating whether or not the left and right pointers are horizontal. TYPE 
Node TRUE END END END END END search; Note that the actions to be taken for node rearrangement very strongly resemble those developed in the AVL-balanced tree search algorithm. It is evident that all four cases can be implemented by simple pointer rotations AVL-balancing criterion. A performance comparison is therefore both possible and desirable. 
We refrain from involved mathematical analysis and concentrate on some basic differences. It can be proven that the AVL-balanced trees are a subset of the SBB-trees. Hence Define a data structure to represent n-ary trees. Then write a procedure that traverses the n-ary tree and generates a binary tree containing the same elements. Assume that the 
N.Wirth. Algorithms and Data Structures. Oberon version Here we present yet another approach that is basically simple and very efficient in many cases. The fact that it also has some disadvantages is discussed subsequently. The data organization used in this technique is the array structure. H is therefore a mapping transforming keys into array 
The method of key transformations is often used in problem areas where tree structures are comparable competitors. The fundamental difficulty in using a key transformation is that the set of possible key values is much larger than the set of available store addresses The case in which a key other than the desired one is at the identified location 
In the following we shall discuss the choice of a transformation function and methods of collision handling. The principal differences lie in the procedure search and in the replacement of the pointer type Node by the global hash table of words T . The hash function H is the modulus of the table size; quadratic probing was chosen for collision 
Note that it is essential for good performance that the table size be a prime number. Although the meth What we wish to be assured of is that on the average the number of probes is small. The following probabilistic argument reveals that it is even very small. Let us once again assume that all possible keys are equally likely and that the hash 
H distributes them uniformly over the range of table indices. Assume The above analysis was based on the use of a collision handling method that spreads the keys uniformly over the remaining locations. Methods used in practice yield slightly worse performance. Detailed analysis for linear probing yields an expected number of probes as E Certainly 
A fairly good a priori estimate of the number of data items to be classified is therefore mandatory if either poor storage utilization or poor performance Devise a scheme that performs insertions and deletions in a hash table using quadratic increments for collision resolution. Compare this scheme experimentally with the straight binary tree 
The primary drawback of the hash table technique is that the size of the table has to be fixed at a time when the actual number of entries is not known. Assume that your computer system incorporates a dynamic storage allocation mechanism that allows to obtain storage at any time. 